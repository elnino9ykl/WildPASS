import numpy as np
import torch
import numbers
import random

from PIL import Image, ImageOps

def colormap_cityscapes(n):
    cmap=np.zeros([n, 3]).astype(np.uint8)
    cmap[0,:] = np.array([128, 64,128])
    cmap[1,:] = np.array([244, 35,232])
    cmap[2,:] = np.array([ 70, 70, 70])
    cmap[3,:] = np.array([ 102,102,156])
    cmap[4,:] = np.array([ 190,153,153])
    cmap[5,:] = np.array([ 153,153,153])

    cmap[6,:] = np.array([ 250,170, 30])
    cmap[7,:] = np.array([ 220,220,  0])
    cmap[8,:] = np.array([ 107,142, 35])
    cmap[9,:] = np.array([ 152,251,152])
    cmap[10,:] = np.array([ 70,130,180])

    cmap[11,:] = np.array([ 220, 20, 60])
    cmap[12,:] = np.array([ 255,  0,  0])
    cmap[13,:] = np.array([ 0,  0,142])
    cmap[14,:] = np.array([  0,  0, 70])
    cmap[15,:] = np.array([  0, 60,100])

    cmap[16,:] = np.array([  0, 80,100])
    cmap[17,:] = np.array([  0,  0,230])
    cmap[18,:] = np.array([ 119, 11, 32])
    cmap[19,:] = np.array([ 0,  0,  0])
    
    return cmap

def colormap_mapillary(n):
    cmap=np.zeros([n, 3]).astype(np.uint8)
    cmap[0,:] = np.array([153,153,153])#pole
    cmap[1,:] = np.array([210,170,100])#street light
    cmap[2,:] = np.array([220,220,220])#billboard
    cmap[3,:] = np.array([250,170, 30])#traffic light
    cmap[4,:] = np.array([  0,  0,142])#car
    
    cmap[5,:] = np.array([  0,  0, 70])#truck
    cmap[6,:] = np.array([119, 11, 32])#bicycle
    cmap[7,:] = np.array([  0,  0,230])#motorcycle
    cmap[8,:] = np.array([  0, 60,100])#bus
    cmap[9,:] = np.array([220,220,  0])#traffic sign front

    cmap[10,:]= np.array([192,192,192])#traffic sign back
    cmap[11,:]= np.array([128, 64,128])#road
    cmap[12,:]= np.array([244, 35,232])#sidewalk
    cmap[13,:]= np.array([196,196,196])#curb
    cmap[14,:]= np.array([190,153,153])#fence
    
    cmap[15,:]= np.array([102,102,156])#wall
    cmap[16,:]= np.array([ 70, 70, 70])#building
    cmap[17,:]= np.array([220, 20, 60])#person
    cmap[18,:]= np.array([255,  0,100])#motorcylist
    cmap[19,:]= np.array([255,  0,  0])#bicylist
    
    cmap[20,:]= np.array([ 70,130,180])#sky
    cmap[21,:]= np.array([107,142, 35])#vegetation
    cmap[22,:]= np.array([152,251,152])#terrain
    cmap[23,:]= np.array([255,255,255])#general marking
    cmap[24,:]= np.array([200,128,128])#crosswalk zebra

    cmap[25,:]= np.array([  0,  0,  0])
    
    return cmap

def colormap_ade20k(n):
    cmap=np.zeros([n, 3]).astype(np.uint8)
    cmap[0,:] = np.array([120,120,120])#wall
    cmap[1,:] = np.array([180,120,120])#building
    cmap[2,:] = np.array([  6,230,230])#sky
    cmap[3,:] = np.array([ 80, 50, 50])#floor
    cmap[4,:] = np.array([  4,200,  3])#tree
    
    cmap[5,:] = np.array([120,120, 80])#ceiling
    cmap[6,:] = np.array([140,140,140])#road
    cmap[7,:] = np.array([204,  5,255])#bed
    cmap[8,:] = np.array([230,230,230])#window
    cmap[9,:] = np.array([  4,250,  7])#grass

    cmap[10,:]= np.array([224,  5,255])#cabinet
    cmap[11,:]= np.array([235,255,  7])#sidewalk
    cmap[12,:]= np.array([150,  5, 61])#person
    cmap[13,:]= np.array([120,120, 70])#ground
    cmap[14,:]= np.array([  8,255, 51])#door
    
    cmap[15,:]= np.array([255,  6, 82])#table
    cmap[16,:]= np.array([204,255,  4])#plant
    cmap[17,:]= np.array([255, 51,  7])#curtain
    cmap[18,:]= np.array([204, 70,  3])#chair
    cmap[19,:]= np.array([  0,102,200])#car
    
    cmap[20,:]= np.array([ 61,230,250])#water
    cmap[21,:]= np.array([255,  6, 51])#painting
    cmap[22,:]= np.array([ 11,102,255])#sofa
    cmap[23,:]= np.array([255,  7, 71])#shelf
    cmap[24,:]= np.array([  9,  7,230])#sea

    cmap[25,:]= np.array([220,220,220])#mirror
    cmap[26,:]= np.array([255,  9, 92])#carpet
    cmap[27,:]= np.array([112,  9,255])#field
    cmap[28,:]= np.array([  8,255,214])#armchair
    cmap[29,:]= np.array([  7,255,214])#seat
    
    cmap[30,:]= np.array([255,184,  6])#fence
    cmap[31,:]= np.array([ 10,255, 71])#desk
    cmap[32,:]= np.array([255, 41, 10])#rock
    cmap[33,:]= np.array([  7,255,255])#closet
    cmap[34,:]= np.array([224,255,  8])#lamp

    cmap[35,:]= np.array([102,  8,255])#tub
    cmap[36,:]= np.array([255,194,  7])#cusion
    cmap[37,:]= np.array([  0,255, 20])#box
    cmap[38,:]= np.array([255,  8, 41])#pillar
    cmap[39,:]= np.array([255,  5,153])#sign
    
    cmap[40,:]= np.array([  0,163,255])#sink
    cmap[41,:]= np.array([255, 31,  0])#path
    cmap[42,:]= np.array([255,224,  0])#stairs
    cmap[43,:]= np.array([  0,235,255])#pillow
    cmap[44,:]= np.array([ 31,  0,255])#stairway

    cmap[45,:]= np.array([255,173,  0])#light
    cmap[46,:]= np.array([  0, 71,255])#street light    
    cmap[47,:]= np.array([ 61,230,250])#pole
    cmap[48,:]= np.array([255,  6, 51])#escalator
    cmap[49,:]= np.array([ 11,102,255])#step

    cmap[50,:]= np.array([  0,  0,  0])
    
    return cmap


def colormap(n):
    cmap=np.zeros([n, 3]).astype(np.uint8)

    for i in np.arange(n):
        r, g, b = np.zeros(3)

        for j in np.arange(8):
            r = r + (1<<(7-j))*((i&(1<<(3*j))) >> (3*j))
            g = g + (1<<(7-j))*((i&(1<<(3*j+1))) >> (3*j+1))
            b = b + (1<<(7-j))*((i&(1<<(3*j+2))) >> (3*j+2)) 

        cmap[i,:] = np.array([r, g, b])

    return cmap

class Relabel:

    def __init__(self, olabel, nlabel):
        self.olabel = olabel
        self.nlabel = nlabel

    def __call__(self, tensor):
        assert (isinstance(tensor, torch.LongTensor) or isinstance(tensor, torch.ByteTensor)) , 'tensor needs to be LongTensor'
        tensor[tensor == self.olabel] = self.nlabel
        return tensor

class ToLabel:

    def __call__(self, image):
        return torch.from_numpy(np.array(image)).long().unsqueeze(0)


class Colorize:

    def __init__(self, n=26):
        #self.cmap = colormap(256)
        #self.cmap = colormap_cityscapes(256)
        self.cmap = colormap_mapillary(256)
        #self.cmap = colormap_ade20k(256)
        self.cmap[n] = self.cmap[-1]
        self.cmap = torch.from_numpy(self.cmap[:n])

    def __call__(self, gray_image):
        size = gray_image.size()
        #print(size)
        color_image = torch.ByteTensor(3, size[1], size[2]).fill_(0)
        #color_image = torch.ByteTensor(3, size[0], size[1]).fill_(0)

        #for label in range(1, len(self.cmap)):
        for label in range(0, len(self.cmap)):
            mask = gray_image[0] == label
            #mask = gray_image == label

            color_image[0][mask] = self.cmap[label][0]
            color_image[1][mask] = self.cmap[label][1]
            color_image[2][mask] = self.cmap[label][2]

        return color_image


## For drnet


class RandomCrop(object):
    def __init__(self, size):
        if isinstance(size, numbers.Number):
            self.size = (int(size), int(size))
        else:
            self.size = size

    def __call__(self, image, label, *args):
        assert label is None or image.size == label.size, \
            "image and label doesn't have the same size {} / {}".format(
                image.size, label.size)

        w, h = image.size
        tw, th = self.size
        top = bottom = left = right = 0
        if w < tw:
            left = (tw - w) // 2
            right = tw - w - left
        if h < th:
            top = (th - h) // 2
            bottom = th - h - top
        if left > 0 or right > 0 or top > 0 or bottom > 0:
            label = pad_image(
                'constant', label, top, bottom, left, right, value=255)
            image = pad_image(
                'reflection', image, top, bottom, left, right)
        w, h = image.size
        if w == tw and h == th:
            return (image, label, *args)

        x1 = random.randint(0, w - tw)
        y1 = random.randint(0, h - th)
        results = [image.crop((x1, y1, x1 + tw, y1 + th))]
        if label is not None:
            results.append(label.crop((x1, y1, x1 + tw, y1 + th)))
        results.extend(args)
        return results


class RandomScale(object):
    def __init__(self, scale):
        if isinstance(scale, numbers.Number):
            scale = [1 / scale, scale]
        self.scale = scale

    def __call__(self, image, label):
        ratio = random.uniform(self.scale[0], self.scale[1])
        w, h = image.size
        tw = int(ratio * w)
        th = int(ratio * h)
        if ratio == 1:
            return image, label
        elif ratio < 1:
            interpolation = Image.ANTIALIAS
        else:
            interpolation = Image.CUBIC
        return image.resize((tw, th), interpolation), \
               label.resize((tw, th), Image.NEAREST)


class Resize(object):
    def __init__(self, size):
        
        self.size = size

    def __call__(self, image, label):
        
        return image.resize(self.size, Image.BILINEAR), \
               label.resize(self.size, Image.NEAREST)



class RandomRotate(object):
    """Crops the given PIL.Image at a random location to have a region of
    the given size. size can be a tuple (target_height, target_width)
    or an integer, in which case the target will be of a square shape (size, size)
    """

    def __init__(self, angle):
        self.angle = angle

    def __call__(self, image, label=None, *args):
        assert label is None or image.size == label.size

        w, h = image.size
        p = max((h, w))
        angle = random.randint(0, self.angle * 2) - self.angle

        if label is not None:
            label = pad_image('constant', label, h, h, w, w, value=255)
            label = label.rotate(angle, resample=Image.NEAREST)
            label = label.crop((w, h, w + w, h + h))

        image = pad_image('reflection', image, h, h, w, w)
        image = image.rotate(angle, resample=Image.BILINEAR)
        image = image.crop((w, h, w + w, h + h))
        return image, label


class RandomHorizontalFlip(object):
    """Randomly horizontally flips the given PIL.Image with a probability of 0.5
    """

    def __call__(self, image, label):
        if random.random() < 0.5:
            results = [image.transpose(Image.FLIP_LEFT_RIGHT),
                       label.transpose(Image.FLIP_LEFT_RIGHT)]
        else:
            results = [image, label]
        return results


class Normalize(object):
    """Given mean: (R, G, B) and std: (R, G, B),
    will normalize each channel of the torch.*Tensor, i.e.
    channel = (channel - mean) / std
    """

    def __init__(self, mean, std):
        self.mean = torch.FloatTensor(mean)
        self.std = torch.FloatTensor(std)

    def __call__(self, image, label=None):
        for t, m, s in zip(image, self.mean, self.std):
            t.sub_(m).div_(s)
        if label is None:
            return image,
        else:
            return image, label


def pad_reflection(image, top, bottom, left, right):
    if top == 0 and bottom == 0 and left == 0 and right == 0:
        return image
    h, w = image.shape[:2]
    next_top = next_bottom = next_left = next_right = 0
    if top > h - 1:
        next_top = top - h + 1
        top = h - 1
    if bottom > h - 1:
        next_bottom = bottom - h + 1
        bottom = h - 1
    if left > w - 1:
        next_left = left - w + 1
        left = w - 1
    if right > w - 1:
        next_right = right - w + 1
        right = w - 1
    new_shape = list(image.shape)
    new_shape[0] += top + bottom
    new_shape[1] += left + right
    new_image = np.empty(new_shape, dtype=image.dtype)
    new_image[top:top+h, left:left+w] = image
    new_image[:top, left:left+w] = image[top:0:-1, :]
    new_image[top+h:, left:left+w] = image[-1:-bottom-1:-1, :]
    new_image[:, :left] = new_image[:, left*2:left:-1]
    new_image[:, left+w:] = new_image[:, -right-1:-right*2-1:-1]
    return pad_reflection(new_image, next_top, next_bottom,
                          next_left, next_right)


def pad_constant(image, top, bottom, left, right, value):
    if top == 0 and bottom == 0 and left == 0 and right == 0:
        return image
    h, w = image.shape[:2]
    new_shape = list(image.shape)
    new_shape[0] += top + bottom
    new_shape[1] += left + right
    new_image = np.empty(new_shape, dtype=image.dtype)
    new_image.fill(value)
    new_image[top:top+h, left:left+w] = image
    return new_image


def pad_image(mode, image, top, bottom, left, right, value=0):
    if mode == 'reflection':
        return Image.fromarray(
            pad_reflection(np.asarray(image), top, bottom, left, right))
    elif mode == 'constant':
        return Image.fromarray(
            pad_constant(np.asarray(image), top, bottom, left, right, value))
    else:
        raise ValueError('Unknown mode {}'.format(mode))


class Pad(object):
    """Pads the given PIL.Image on all sides with the given "pad" value"""

    def __init__(self, padding, fill=0):
        assert isinstance(padding, numbers.Number)
        assert isinstance(fill, numbers.Number) or isinstance(fill, str) or \
               isinstance(fill, tuple)
        self.padding = padding
        self.fill = fill

    def __call__(self, image, label=None, *args):
        if label is not None:
            label = pad_image(
                'constant', label,
                self.padding, self.padding, self.padding, self.padding,
                value=255)
        if self.fill == -1:
            image = pad_image(
                'reflection', image,
                self.padding, self.padding, self.padding, self.padding)
        else:
            image = pad_image(
                'constant', image,
                self.padding, self.padding, self.padding, self.padding,
                value=self.fill)
        return (image, label, *args)


class PadImage(object):
    def __init__(self, padding, fill=0):
        assert isinstance(padding, numbers.Number)
        assert isinstance(fill, numbers.Number) or isinstance(fill, str) or \
               isinstance(fill, tuple)
        self.padding = padding
        self.fill = fill

    def __call__(self, image, label=None, *args):
        if self.fill == -1:
            image = pad_image(
                'reflection', image,
                self.padding, self.padding, self.padding, self.padding)
        else:
            image = ImageOps.expand(image, border=self.padding, fill=self.fill)
        return (image, label, *args)


class ToTensor(object):
    """Converts a PIL.Image or numpy.ndarray (H x W x C) in the range
    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].
    """

    def __call__(self, pic, label=None):
        if isinstance(pic, np.ndarray):
            # handle numpy array
            img = torch.from_numpy(pic)
        else:
            # handle PIL Image
            img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))
            # PIL image mode: 1, L, P, I, F, RGB, YCbCr, RGBA, CMYK
            if pic.mode == 'YCbCr':
                nchannel = 3
            else:
                nchannel = len(pic.mode)
            img = img.view(pic.size[1], pic.size[0], nchannel)
            # put it from HWC to CHW format
            # yikes, this transpose takes 80% of the loading time/CPU
            img = img.transpose(0, 1).transpose(0, 2).contiguous()
        img = img.float().div(255)
        if label is None:
            return img,
        else:
            return img, torch.LongTensor(np.array(label, dtype=np.int)).unsqueeze(0)


class Compose(object):
    """Composes several transforms together.
    """

    def __init__(self, transforms):
        self.transforms = transforms

    def __call__(self, *args):
        for t in self.transforms:
            args = t(*args)
        return args


